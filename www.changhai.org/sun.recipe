#!/usr/bin/python
# -*- coding: utf-8 -*-

import mechanize
from calibre.web.feeds.news import BasicNewsRecipe

class AdvancedUserRecipeMineTest(BasicNewsRecipe):
  """
    Recipe for download 太阳的故事
    http://www.changhai.org/articles/science/astronomy/sun/
  """
  title = u'太阳的故事'
  INDEX = 'http://www.changhai.org/articles/science/astronomy/sun/'
  
  __author__ = u'卢昌海'
  __version__ = '1.0'
  language = 'zh-CN'
  pubisher = '卢昌海'
  description = u''
  category = 'Science, Chinese'
  remove_javascript = True
  use_embedded_content = False
  no_stylesheets = True
  encoding = 'UTF-8'
  conversion_options = {'linearize_tables':True}
  keep_only_tags = [
    dict(name='table', attrs={'id':['main-body']}),
  ]

  remove_tags = [
    dict(name='p', attrs={'class':['left', 'right']}),
  ]
  remove_tags_after = [
    dict(name='p', attrs = {'class' : ['article-date-claim']}),
  ]

  _cachedBrowser = None
  def get_browser(self):
    """
      The images on this site requires Referer to download,
      otherwise it gets 403 Forbidden error.
      So it has to append HTTP Referer HEAD in its request
    """
    if self._cachedBrowser is None:
      br = BasicNewsRecipe.get_browser(self)
      orig_open_novisit = br.open_novisit
      def my_open_no_visit(url, **kwargs):
        req = mechanize.Request( url, headers = { 'Referer': self.INDEX, })
        return orig_open_novisit(req)
      br.open_novisit = my_open_no_visit
      #br.set_debug_http(True)
      self._cachedBrowser = br
    return br

  def clone_browser(self, br):
    if self._cachedBrowser is None:
      raise Exception("No browser")
    br = BasicNewsRecipe.clone_browser(self, br)
    br.open_novisit = self._cachedBrowser.open_novisit
    return br
  
  def parse_index(self):
    articles = []
    feeds = []

    soup = self.index_to_soup(self.INDEX)
    feed_title = self.tag_to_string(soup.find('title'))
    self.log.debug("Feed Title: " + feed_title)
    
    for table in soup.findAll('table', attrs={'class':'inside-article'}):
      # Main articles
      for post in table.findAll('li'):
        a = post.find('a', href=True)
        title = self.tag_to_string(post)
        url = a['href']
        if "#" not in url:
          self.log.debug("Article title and url: ")
          self.log.debug(title + ": " + url)
          url = self.INDEX + url
          articles.append((
            {'title':title,
             'url':url,
             'description':'',
             'date':''}))

      # 参考文献, etc
      for post in soup.findAll('p', attrs={'class':'center'}):
        for a in post.findAll('a', href=True):
          title = self.tag_to_string(a)
          url = a['href']
          self.log.debug("Article title and url: ")
          self.log.debug(title + ": " + url)
          url = self.INDEX + a['href']
          articles.append((
            {'title':title,
             'url':url,
             'description':'',
             'date':''}))
    if articles:
      feeds.append((feed_title, articles))
    return feeds



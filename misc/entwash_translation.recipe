#!/usr/bin/python
# -*- coding: utf-8 -*-

import mechanize
from calibre.web.feeds.news import BasicNewsRecipe

class AdvancedUserRecipeMineTest(BasicNewsRecipe):
  """
    Recipe for Ent Blog的译文
    http://entwash.blogbus.com/tag/%E8%AF%91%E6%96%87
  """
  title = u'Ent Blog 译文'
  INDEX = 'http://entwash.blogbus.com/tag/%E8%AF%91%E6%96%87'
  
  __author__ = u'Ent'
  __version__ = '1.0'
  language = 'zh-CN'
  pubisher = u'Unknown'
  description = u''
  category = 'Sci Fi, Chinese'
  remove_javascript = True
  use_embedded_content = False
  no_stylesheets = True
  encoding = 'UTF-8'
  conversion_options = {'linearize_tables':True}
  keep_only_tags = [
    dict(name='div', attrs= {'class' : ['postBody']}),
  ]
  remove_tags = [
    dict(name='div', attrs= {'id':['bdshare']}),
  ]
  _cachedBrowser = None
  def get_browser(self):
    """
      The images on this site requires Referer to download,
      otherwise it gets 403 Forbidden error.
      So it has to append HTTP Referer HEAD in its request
    """
    if self._cachedBrowser is None:
      br = BasicNewsRecipe.get_browser(self)
      orig_open_novisit = br.open_novisit
      def my_open_no_visit(url, **kwargs):
        req = mechanize.Request( url, headers = { 'Referer': self.INDEX, })
        return orig_open_novisit(req)
      br.open_novisit = my_open_no_visit
      #br.set_debug_http(True)
      self._cachedBrowser = br
    return self._cachedBrowser

  def clone_browser(self, br):
    if self._cachedBrowser is None:
      raise Exception("No browser")
    br = BasicNewsRecipe.clone_browser(self, br)
    br.open_novisit = self._cachedBrowser.open_novisit
    return br
  
  def parse_index(self):
    articles = []
    feeds = []

    soup = self.index_to_soup(self.INDEX)
    feed_title = self.tag_to_string(soup.find('title'))
    self.log.debug("Feed Title: " + feed_title)
    
    for table in soup.findAll('div', attrs={'id':'content'}):
      # Main articles
      for post in table.findAll('div', attrs={'class':'postHeader'}):
        a = post.find('a', href=True)
        url = a['href']
        title = self.tag_to_string(a)
        if "#" not in url:
          self.log.debug("Article title and url: ")
          self.log.debug(title + ": " + url)
          articles.append((
            {'title':title,
             'url':url,
             'description':'',
             'date':''}))
    articles.reverse()
    if articles:
      feeds.append((feed_title, articles))
    return feeds


